{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Intro-to-Pytorch\" data-toc-modified-id=\"Intro-to-Pytorch-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Intro to Pytorch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pytorch-tensors\" data-toc-modified-id=\"Pytorch-tensors-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Pytorch tensors</a></span></li><li><span><a href=\"#Pytorch-Autograd\" data-toc-modified-id=\"Pytorch-Autograd-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Pytorch Autograd</a></span></li><li><span><a href=\"#torch.nn-module\" data-toc-modified-id=\"torch.nn-module-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>torch.nn module</a></span></li></ul></li><li><span><a href=\"#Linear-Regression-with-Pytorch\" data-toc-modified-id=\"Linear-Regression-with-Pytorch-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Linear Regression with Pytorch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gradient-Descent-with-Pytorch\" data-toc-modified-id=\"Gradient-Descent-with-Pytorch-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Gradient Descent with Pytorch</a></span></li><li><span><a href=\"#Simplified-GD-Loop\" data-toc-modified-id=\"Simplified-GD-Loop-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Simplified GD Loop</a></span><ul class=\"toc-item\"><li><span><a href=\"#Models-in-Pytorch\" data-toc-modified-id=\"Models-in-Pytorch-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Models in Pytorch</a></span></li></ul></li></ul></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#How-to-take-a-vector-back-to-numpy?\" data-toc-modified-id=\"How-to-take-a-vector-back-to-numpy?-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>How to take a vector back to numpy?</a></span></li><li><span><a href=\"#Exercise:\" data-toc-modified-id=\"Exercise:-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Exercise:</a></span></li></ul></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch libraries\n",
    "%matplotlib inline\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch consists of 4 main packages:\n",
    "* torch: a general purpose array library similar to Numpy that can do computations on GPU\n",
    "* torch.autograd: a package for automatically obtaining gradients\n",
    "* torch.nn: a neural net library with common layers and cost functions\n",
    "* torch.optim: an optimization package with common optimization algorithms like SGD, Adam, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch tensors\n",
    "Like Numpy tensors but can utilize GPUs to accelerate its numerical computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random tensor\n",
    "N = 5\n",
    "x = torch.randn(N, 10).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0916, -3.1099, -1.7503, -0.1792,  0.4360,  0.6777, -1.7102, -0.2961,\n",
       "          1.9286,  0.2614],\n",
       "        [ 0.3374, -0.9188,  0.4304,  0.9976,  1.3648,  1.6387, -0.8623, -1.6445,\n",
       "         -0.7616, -1.8828],\n",
       "        [ 0.1270,  0.7313,  1.0642, -0.4633, -0.3218, -2.0507, -0.4120,  1.3823,\n",
       "          1.7255,  0.4881],\n",
       "        [-0.8051,  0.2956, -1.3144, -0.9972,  1.0103, -0.2424,  0.0383, -0.7359,\n",
       "          0.0584, -0.7746],\n",
       "        [ 1.1757, -0.3414,  0.6303,  0.0712,  0.0444, -0.0482,  2.4833,  2.4405,\n",
       "          1.8376, -0.4547]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0916, -3.1099, -1.7503, -0.1792,  0.4360,  0.6777, -1.7102, -0.2961,\n",
       "          1.9286,  0.2614,  0.3374, -0.9188,  0.4304,  0.9976,  1.3648,  1.6387,\n",
       "         -0.8623, -1.6445, -0.7616, -1.8828,  0.1270,  0.7313,  1.0642, -0.4633,\n",
       "         -0.3218, -2.0507, -0.4120,  1.3823,  1.7255,  0.4881, -0.8051,  0.2956,\n",
       "         -1.3144, -0.9972,  1.0103, -0.2424,  0.0383, -0.7359,  0.0584, -0.7746,\n",
       "          1.1757, -0.3414,  0.6303,  0.0712,  0.0444, -0.0482,  2.4833,  2.4405,\n",
       "          1.8376, -0.4547]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping of tensors using .view()\n",
    "x.view(1,-1) #-1 makes torch infer the second dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Autograd\n",
    "The autograd package in PyTorch provides classes and functions implementing automatic differentiation of arbitrary scalar valued function. For example, the gradient of the error with respect to all parameters.\n",
    "\n",
    "In order for this to happen we need to declare our paramerers as Tensors with the requires_grad=True keyword. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3., 4., 5., 6.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(888., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = (2*x**3 +1).sum()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.backward() # computes the grad of L with respect to x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  8.,  26.,  56.,  98., 152., 218.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6872, -0.2684, -1.8404],\n",
       "        [-1.9067, -0.4068, -2.3911]], requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is another example\n",
    "x = torch.randn(2, 3)\n",
    "x.requires_grad = True\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13.4496, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = (x**2).sum()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3744, -0.5368, -3.6809],\n",
       "        [-3.8133, -0.8137, -4.7821]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.backward()\n",
    "x.grad # note, it is the same shape as x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn module\n",
    "A neural net library with common layers and cost functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Linear(5, 3)` creates a linear transformation ($A\\cdot X+b$) of a $N \\times 5$ matrix into a $N \\times 3$ matrix, where N can be anything (number of observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5 # number of input featutes\n",
    "M = 3 # neurons in the first hidden layer\n",
    "linear_map = nn.Linear(D, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.1471,  0.2945, -0.0033, -0.2893, -0.3564],\n",
       "         [-0.0254,  0.0652, -0.0652, -0.4145,  0.1161],\n",
       "         [ 0.3796,  0.2814, -0.1130, -0.1134, -0.1553]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1556, -0.0149,  0.0407], requires_grad=True)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters are initialized randomly\n",
    "[p for p in linear_map.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([3, 5]), torch.Size([3])]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in linear_map.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Linear Regression with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of linear regression is to fit a line to a set of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we generate some fake data\n",
    "def lin(a,b,x): return a*x+b\n",
    "\n",
    "def gen_fake_data(n, a, b):\n",
    "    x = np.random.uniform(0,1,n) \n",
    "    y = lin(a,b,x) + 0.1 * np.random.normal(0,3,n)\n",
    "    return x, y\n",
    "\n",
    "x, y = gen_fake_data(50, 3., 8.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x,y, s=8); plt.xlabel(\"x\"); plt.ylabel(\"y\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to find **parameters** (weights) $a$ and $b$ such that you minimize the *error* between the points and the line $a\\cdot x + b$. Note that here $a$ and $b$ are unknown. For a regression problem the most common *error function* or *loss function* is the **mean squared error** ($\\sum_i (\\hat{y}_i - y_i)^2$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_hat, y): return ((y_hat - y) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we believe $a = 10$ and $b = 5$ then we can compute `y_hat` which is our *prediction* and then compute our error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.839383464124564"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = lin(10,5,x)\n",
    "mse(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(a, b, x, y): return mse(lin(a,b,x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.839383464124564"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss(10, 5, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have specified the *model* (linear regression) and the *evaluation criteria* (or *loss function*). Now we need to handle *optimization*; that is, how do we find the best values for $a$ and $b$? How do we find the best *fitting* linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a fixed dataset $x$ and $y$ `mse_loss(a,b)` is a function of $a$ and $b$. We would like to find the values of $a$ and $b$ that minimize that function.\n",
    "\n",
    "**Gradient descent** is an algorithm that minimizes functions. Given a function defined by a set of parameters, gradient descent starts with an initial set of parameter values and iteratively moves toward a set of parameter values that minimize the function. This iterative minimization is achieved by taking steps in the negative direction of the function gradient.\n",
    "\n",
    "Here is gradient descent implemented in [PyTorch](http://pytorch.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate some more data\n",
    "x, y = gen_fake_data(10000, 3., 8.)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap x and y as tensor \n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0154], dtype=torch.float64, requires_grad=True),\n",
       " tensor([0.4714], dtype=torch.float64, requires_grad=True))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random Tensors for weights, and wrap them in tensors.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these tensors during the backward pass.\n",
    "a, b = np.random.randn(1), np.random.randn(1)\n",
    "a = torch.tensor(a, requires_grad=True)\n",
    "b = torch.tensor(b, requires_grad=True)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.0379068143345\n",
      "0.709158747200683\n",
      "0.2198650502216468\n",
      "0.18786220580080568\n",
      "0.16543229076238342\n",
      "0.14822094813301154\n",
      "0.13500381930083474\n",
      "0.12485390855977307\n",
      "0.11705942500598601\n",
      "0.11107375917646536\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    loss = mse_loss(a,b,x,y)\n",
    "    if t % 1000 == 0: print(loss.item())\n",
    "    \n",
    "    # Computes the gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this call a.grad and b.grad will be Variables holding the gradient\n",
    "    # of the loss with respect to a and b respectively\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update a and b using gradient descent; a.data and b.data are Tensors,\n",
    "    # a.grad and b.grad are Variables and a.grad.data and b.grad.data are Tensors\n",
    "    a.data -= learning_rate * a.grad.data\n",
    "    b.data -= learning_rate * b.grad.data\n",
    "    \n",
    "    # Zero the gradients\n",
    "    a.grad.data.zero_()\n",
    "    b.grad.data.zero_()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.4279], dtype=torch.float64, requires_grad=True) tensor([7.7721], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified GD Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear tranformation with input dimension=1 and output dimension=1\n",
    "nn.Linear(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple way of specifying a linear regression model\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(1, 1),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent way of specifiying the same model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        return x \n",
    "model =  LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.8628]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2933], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# note here we have just two parameters, why?\n",
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = gen_fake_data(10000, 3., 8.)\n",
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you have to be careful with the dimensions that your model is expecting\n",
    "x = torch.unsqueeze(x, 1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2683],\n",
      "        [-0.1034],\n",
      "        [ 0.1322],\n",
      "        ...,\n",
      "        [-0.4851],\n",
      "        [-0.1643],\n",
      "        [-0.2746]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "y_hat = model(x)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(94.2142, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.unsqueeze(1)\n",
    "F.mse_loss(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data\n",
    "x_val, y_val = gen_fake_data(1000, 3., 8.)\n",
    "x_val = torch.tensor(x_val).float().unsqueeze(1)\n",
    "y_val = torch.tensor(y_val).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the optim package to define an Optimizer that will update the \n",
    "# weights of\n",
    "# the model for us. Here we will use Adam\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 91.278 valid loss 88.600\n",
      "train loss 0.109 valid loss 0.108\n",
      "train loss 0.096 valid loss 0.094\n",
      "train loss 0.093 valid loss 0.091\n",
      "train loss 0.092 valid loss 0.089\n",
      "train loss 0.091 valid loss 0.089\n",
      "train loss 0.091 valid loss 0.089\n",
      "train loss 0.091 valid loss 0.089\n",
      "train loss 0.091 valid loss 0.089\n",
      "train loss 0.091 valid loss 0.089\n"
     ]
    }
   ],
   "source": [
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    model.train() # some layers have different behavior during train/and evaluation\n",
    "    y_hat = model(x)\n",
    "    loss = F.mse_loss(y_hat, y)\n",
    "       \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # checking validation loss\n",
    "    model.eval()  # some layers have different behavior during train/and evaluation\n",
    "    y_hat_val = model(x_val)\n",
    "    val_loss = F.mse_loss(y_hat_val, y_val)\n",
    "    \n",
    "    if t % 1000 == 0: print(\"train loss %.3f valid loss %.3f\" % (loss.item(), val_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[2.9982]], requires_grad=True), Parameter containing:\n",
      "tensor([8.0014], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating fake data\n",
    "# Here we generate some fake data\n",
    "def lin(a,b,x): return a*x+b\n",
    "\n",
    "def gen_logistic_fake_data(n, a, b):\n",
    "    x = np.random.uniform(-20,20, (n, 2))\n",
    "    x2_hat = lin(a,b, x[:,0])\n",
    "    y = x[:,1] > x2_hat\n",
    "    return x, y.astype(int)\n",
    "\n",
    "x, y = gen_logistic_fake_data(100, 1., 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff205dc3150>]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.arange(-20, 20, 0.2)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x[:,0],x[:,1],c=y, s=8);\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\");\n",
    "plt.plot(t, t + 0.5, 'r--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 1),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating train and val data\n",
    "x, y = gen_logistic_fake_data(10000, 1., 0.5)\n",
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float().unsqueeze(1)\n",
    "\n",
    "x_val, y_val = gen_logistic_fake_data(1000, 1., 0.5)\n",
    "x_val = torch.tensor(x_val).float()\n",
    "y_val = torch.tensor(y_val).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 2.279 valid loss 1.155\n",
      "train loss 0.015 valid loss 0.015\n",
      "train loss 0.010 valid loss 0.011\n",
      "train loss 0.007 valid loss 0.008\n",
      "train loss 0.006 valid loss 0.007\n",
      "train loss 0.005 valid loss 0.006\n",
      "train loss 0.004 valid loss 0.005\n",
      "train loss 0.003 valid loss 0.005\n",
      "train loss 0.002 valid loss 0.004\n",
      "train loss 0.002 valid loss 0.004\n"
     ]
    }
   ],
   "source": [
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    model.train()\n",
    "    y_hat = model(x)\n",
    "    loss = F.binary_cross_entropy(torch.sigmoid(y_hat), y)\n",
    "       \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    y_hat_val = model(x_val)\n",
    "    val_loss = F.binary_cross_entropy(torch.sigmoid(y_hat_val), y_val)\n",
    "    \n",
    "    if t % 1000 == 0: print(\"train loss %.3f valid loss %.3f\" % (loss.item(), val_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-18.8909,  18.9085]], requires_grad=True), Parameter containing:\n",
      "tensor([-9.4594], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to take a vector back to numpy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = gen_logistic_fake_data(10, 1., 0.5)\n",
    "x = torch.tensor(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.122741  ,   0.19566005],\n",
       "       [  6.1833034 ,  -6.8303604 ],\n",
       "       [ -8.404926  , -19.9767    ],\n",
       "       [  6.541304  ,  11.745924  ],\n",
       "       [ -8.046523  , -13.91099   ],\n",
       "       [ 14.32502   ,  10.492154  ],\n",
       "       [-12.88226   ,  13.885471  ],\n",
       "       [-12.953713  ,  -7.2117085 ],\n",
       "       [-19.711988  ,  -9.144359  ],\n",
       "       [-17.811853  ,   7.4456882 ]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "Compute the accuracy of the validation logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# References\n",
    "* https://pytorch.org/docs/stable/index.html\n",
    "* http://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "* https://hsaghir.github.io/data_science/pytorch_starter/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "116px",
    "width": "251px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
